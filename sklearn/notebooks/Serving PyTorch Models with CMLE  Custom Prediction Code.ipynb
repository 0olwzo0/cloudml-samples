{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serving PyTorch Models with CMLE  Custom Prediction Code\n",
    "\n",
    "Cloud ML Engine Online Prediction now supports custom python code in two forms:\n",
    "\n",
    "1. Custom transforms in scikit-learn pipelines.\n",
    "2. Custom prediction routine, including custom pre/post processing, and/or models not created by the scikit-learn framework.\n",
    "\n",
    "In this notebook, we show how to deploy a model created by [PyTorch](https://pytorch.org/) using CMLE  Custom Prediction Code\n",
    "\n",
    "**Note**: You must be whitelisted to use the custom code feature. Please fill out [this google form](https://docs.google.com/forms/d/e/1FAIpQLSc6fxgXQIyA6BDLfCKOJPu5CyCuOB_M_rGTws0629od5mlznw/viewform) to get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Before we start let's install gcloud tool so we can interact with Google Cloud Machine Learning Engine easier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: google-cloud in /Users/khalidsalama/Technology/python-venvs/py27-venv/lib/python2.7/site-packages (0.34.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -U google-cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also define the project name, model name, the gcs bucket name that we'll refer to later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "ksalama-gcp-playground\n"
     ]
    }
   ],
   "source": [
    "PROJECT='ksalama-gcp-playground' \n",
    "BUCKET='ksalama-gcs-cloudml'\n",
    "REGION='europe-west1'\n",
    "\n",
    "!gcloud config set project {PROJECT}\n",
    "!gcloud config get-value project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download iris data\n",
    "In this example, we want to build a classifier for the simple [iris dataset](https://archive.ics.uci.edu/ml/datasets/iris). So first, we download the data csv file locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: data: File exists\n",
      "mkdir: models: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir data\n",
    "!mkdir models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('data/iris.csv', <httplib.HTTPMessage instance at 0x1080925a8>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib\n",
    "\n",
    "LOCAL_DATA_DIR = \"data/iris.csv\"\n",
    "\n",
    "url_opener = urllib.URLopener()\n",
    "url_opener.retrieve(\"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\", LOCAL_DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Build a PyTorch NN Classifier\n",
    "\n",
    "Make sure that pytorch package is [installed](https://pytorch.org/get-started/locally/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 0.4.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "print 'PyTorch Version: {}'.format(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data to Pandas Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records loaded: 150\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "datatrain = pd.read_csv(LOCAL_DATA_DIR, names=['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species'])\n",
    "\n",
    "#change string value to numeric\n",
    "datatrain.loc[datatrain['species']=='Iris-setosa', 'species']=0\n",
    "datatrain.loc[datatrain['species']=='Iris-versicolor', 'species']=1\n",
    "datatrain.loc[datatrain['species']=='Iris-virginica', 'species']=2\n",
    "datatrain = datatrain.apply(pd.to_numeric)\n",
    "\n",
    "#change dataframe to array\n",
    "datatrain_array = datatrain.as_matrix()\n",
    "\n",
    "#split x and y (feature and target)\n",
    "xtrain = datatrain_array[:,:4]\n",
    "ytrain = datatrain_array[:,4]\n",
    "\n",
    "print 'Records loaded: {}'.format(len(xtrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = 4\n",
    "hidden_units = 10\n",
    "num_classes = 3\n",
    "learning_rate = 0.1\n",
    "momentum = 0.9\n",
    "num_epoch = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define the PyTorch NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(input_features, hidden_units),\n",
    "    torch.nn.Sigmoid(),\n",
    "    torch.nn.Linear(hidden_units, num_classes),\n",
    "    torch.nn.Softmax()\n",
    ")\n",
    "\n",
    "loss_metric = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate, momentum=momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10000] Loss: 1.107\n",
      "Epoch [1001/10000] Loss: 0.578\n",
      "Epoch [2001/10000] Loss: 0.573\n",
      "Epoch [3001/10000] Loss: 0.571\n",
      "Epoch [4001/10000] Loss: 0.57\n",
      "Epoch [5001/10000] Loss: 0.569\n",
      "Epoch [6001/10000] Loss: 0.568\n",
      "Epoch [7001/10000] Loss: 0.568\n",
      "Epoch [8001/10000] Loss: 0.567\n",
      "Epoch [9001/10000] Loss: 0.567\n",
      "Epoch [10000/10000] Loss: 0.567\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epoch):\n",
    "    \n",
    "    x = Variable(torch.Tensor(xtrain).float())\n",
    "    y = Variable(torch.Tensor(ytrain).long())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    y_pred = model(x)\n",
    "    loss = loss_metric(y_pred, y)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch) % 1000 == 0:\n",
    "        print 'Epoch [{}/{}] Loss: {}'.format(epoch+1, num_epoch, round(loss.item(),3))\n",
    "        \n",
    "print 'Epoch [{}/{}] Loss: {}'.format(epoch+1, num_epoch, round(loss.item(),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save and load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_MODEL_DIR = \"models/model.pt\"\n",
    "\n",
    "torch.save(model, LOCAL_MODEL_DIR)\n",
    "iris_classifier = torch.load(LOCAL_MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test the loaded model for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(instances, vocab):\n",
    "    instances = torch.Tensor(instances)\n",
    "    output = iris_classifier(instances)\n",
    "    _ , predicted = torch.max(output, 1)\n",
    "    return [vocab[class_index] for class_index in predicted]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get predictions for the first 10 instances in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa']\n"
     ]
    }
   ],
   "source": [
    "print predict_class(xtrain[0:10], ['setosa', 'versicolor', 'virginica'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Upload trained model to Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://models/model.pt [Content-Type=application/octet-stream]...\n",
      "/ [1/1 files][  8.2 KiB/  8.2 KiB] 100% Done                                    \n",
      "Operation completed over 1 objects/8.2 KiB.                                      \n",
      "gs://ksalama-gcs-cloudml/models/pytorch/iris_classifier/model.pt\n"
     ]
    }
   ],
   "source": [
    "GCS_MODEL_DIR='models/pytorch/iris_classifier/'\n",
    "\n",
    "!gsutil -m cp -r {LOCAL_MODEL_DIR} gs://{BUCKET}/{GCS_MODEL_DIR}\n",
    "!gsutil ls gs://{BUCKET}/{GCS_MODEL_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Prepare the Custom Prediction Package\n",
    "\n",
    "1. Implement a model **custom class** for pre/post processing, as well as loading and using your model for prediction.\n",
    "2. Prepare yout **setup.py** file, to include all the modules and packages you need in your custome model class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create the custom model class\n",
    "In the **from_path**, you load the pytorch model that you uploaded to GCS. Then in the **predict** method, you use it for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model.py\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from google.cloud import storage\n",
    "import torch\n",
    "\n",
    "class PyTorchIrisClassifier(object):\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        self._model = model\n",
    "        self.class_vocab = ['setosa', 'versicolor', 'virginica']\n",
    "        \n",
    "    @classmethod\n",
    "    def from_path(cls, model_dir):\n",
    "        model_file = os.path.join(model_dir,'model.pt')\n",
    "        model = torch.load(model_file)    \n",
    "        return cls(model)\n",
    "\n",
    "    def predict(self, instances, **kwargs):\n",
    "        data = pd.DataFrame(instances).as_matrix()\n",
    "        inputs = torch.Tensor(data)\n",
    "        outputs = self._model(inputs)\n",
    "        _ , predicted = torch.max(outputs, 1)\n",
    "        return [self.class_vocab[class_index] for class_index in predicted]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create a setup.py module\n",
    "Include **pytorch** as a required package, as well as the **model.py** file that includes your custom model class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile setup.py\n",
    "\n",
    "from setuptools import setup\n",
    "\n",
    "REQUIRED_PACKAGES = ['torch']\n",
    "\n",
    "setup(\n",
    "    name=\"iris-custom-model\",\n",
    "    version=\"0.1\",\n",
    "    scripts=[\"model.py\"],\n",
    "    install_requires=REQUIRED_PACKAGES\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create the package \n",
    "\n",
    "This will create a .tar.gz package under /dist directory. The name of the package will be (name)-(version).tar.gz where (name) and (version) are the ones specified in the setup.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running sdist\n",
      "running egg_info\n",
      "writing requirements to iris_custom_model.egg-info/requires.txt\n",
      "writing iris_custom_model.egg-info/PKG-INFO\n",
      "writing top-level names to iris_custom_model.egg-info/top_level.txt\n",
      "writing dependency_links to iris_custom_model.egg-info/dependency_links.txt\n",
      "reading manifest file 'iris_custom_model.egg-info/SOURCES.txt'\n",
      "writing manifest file 'iris_custom_model.egg-info/SOURCES.txt'\n",
      "warning: sdist: standard file not found: should have one of README, README.rst, README.txt, README.md\n",
      "\n",
      "running check\n",
      "warning: check: missing required meta-data: url\n",
      "\n",
      "warning: check: missing meta-data: either (author and author_email) or (maintainer and maintainer_email) must be supplied\n",
      "\n",
      "creating iris-custom-model-0.1\n",
      "creating iris-custom-model-0.1/iris_custom_model.egg-info\n",
      "copying files to iris-custom-model-0.1...\n",
      "copying model.py -> iris-custom-model-0.1\n",
      "copying setup.py -> iris-custom-model-0.1\n",
      "copying iris_custom_model.egg-info/PKG-INFO -> iris-custom-model-0.1/iris_custom_model.egg-info\n",
      "copying iris_custom_model.egg-info/SOURCES.txt -> iris-custom-model-0.1/iris_custom_model.egg-info\n",
      "copying iris_custom_model.egg-info/dependency_links.txt -> iris-custom-model-0.1/iris_custom_model.egg-info\n",
      "copying iris_custom_model.egg-info/requires.txt -> iris-custom-model-0.1/iris_custom_model.egg-info\n",
      "copying iris_custom_model.egg-info/top_level.txt -> iris-custom-model-0.1/iris_custom_model.egg-info\n",
      "Writing iris-custom-model-0.1/setup.cfg\n",
      "Creating tar archive\n",
      "removing 'iris-custom-model-0.1' (and everything under it)\n"
     ]
    }
   ],
   "source": [
    "!python setup.py sdist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Uploaded the package to GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://./dist/iris-custom-model-0.1.tar.gz [Content-Type=application/x-tar]...\n",
      "/ [1 files][  1.0 KiB/  1.0 KiB]                                                \n",
      "Operation completed over 1 objects/1.0 KiB.                                      \n",
      "gs://ksalama-gcs-cloudml/models/pytorch/packages/iris-custom-model-0.1.tar.gz\n"
     ]
    }
   ],
   "source": [
    "GCS_PACKAGE_URI='models/pytorch/packages/iris-custom-model-0.1.tar.gz'\n",
    "\n",
    "!gsutil cp ./dist/iris-custom-model-0.1.tar.gz gs://{BUCKET}/{GCS_PACKAGE_URI}\n",
    "!gsutil ls gs://{BUCKET}/{GCS_PACKAGE_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Deploy the Model to CMLE for Online Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create CMLE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created ml engine model [projects/ksalama-gcp-playground/models/torch_iris_classifier].\n",
      "\n",
      "torch_iris_classifier\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME='torch_iris_classifier'\n",
    "\n",
    "!gcloud ml-engine models create {MODEL_NAME} --regions {REGION}\n",
    "!echo ''\n",
    "!gcloud ml-engine models list | grep 'torch'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create CMLE model version\n",
    "\n",
    "Once you have your custom package ready, you can specify this as an argument when creating a version resource. Note that you need to provide the path to your package (as package-uris) and also the class name that contains your custom predict method (as model-class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_VERSION='v1'\n",
    "RUNTIME_VERSION='1.10'\n",
    "MODEL_CLASS='model.PyTorchIrisClassifier'\n",
    "\n",
    "!gcloud alpha ml-engine versions create {MODEL_VERSION} --model={MODEL_NAME} \\\n",
    "            --origin=gs://{BUCKET}/{GCS_MODEL_DIR} \\\n",
    "            --runtime-version={RUNTIME_VERSION} \\\n",
    "            --framework='SCIKIT_LEARN' \\\n",
    "            --python-version=2.7 \\\n",
    "            --package-uris=gs://{BUCKET}/{GCS_PACKAGE_URI}\\\n",
    "            --model-class={MODEL_CLASS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME  DEPLOYMENT_URI                                           STATE\r\n",
      "v1    gs://ksalama-gcs-cloudml/models/pytorch/iris_classifier  READY\r\n"
     ]
    }
   ],
   "source": [
    "!gcloud ml-engine versions list --model {MODEL_NAME}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D. CMLE Online Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient import discovery\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "credentials = GoogleCredentials.get_application_default()\n",
    "api = discovery.build('ml', 'v1', credentials=credentials,\n",
    "                      discoveryServiceUrl='https://storage.googleapis.com/cloud-ml/discovery/ml_v1_discovery.json')\n",
    "\n",
    "\n",
    "def estimate(project, model_name, version, instances):\n",
    "    \n",
    "    request_data = {'instances': instances}\n",
    "\n",
    "    model_url = 'projects/{}/models/{}/versions/{}'.format(project, model_name, version)\n",
    "    response = api.projects().predict(body=request_data, name=model_url).execute()\n",
    "\n",
    "    #print response\n",
    "    \n",
    "    predictions = response[\"predictions\"]\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'VERSION_NAME' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-f248178f5faf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                      \u001b[0;34m,\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPROJECT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                      \u001b[0;34m,\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMODEL_NAME\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                      ,version=VERSION_NAME)\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'VERSION_NAME' is not defined"
     ]
    }
   ],
   "source": [
    "instances = [\n",
    "    [6.8, 2.8, 4.8, 1.4],\n",
    "    [6. , 3.4, 4.5, 1.6]\n",
    "]\n",
    "\n",
    "predictions = estimate(instances=instances\n",
    "                     ,project=PROJECT\n",
    "                     ,model_name=MODEL_NAME\n",
    "                     ,version=VERSION_NAME)\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions? Feedback?\n",
    "Feel free to send us an email (cloudml-feedback@google.com) if you run into any issues or have any questions/feedback!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
